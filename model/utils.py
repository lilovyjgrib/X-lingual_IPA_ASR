# -*- coding: utf-8 -*-
"""conversion_tools

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BCl8mMn1JNyywHv1jX399oXcQH2gbT5x
"""

import torch

def evaluate_PER(model, data_loader):
    model.eval()
    total_phonemes = 0
    total_errors = 0

    with torch.no_grad():
        for x, y, input_lengths, target_lengths in data_loader:
            x, y = x.to(SETTING['device']), y.to(SETTING['device'])
            input_lengths = compute_cnn_output_lengths(model, input_lengths).to(SETTING['device'])
            target_lengths = target_lengths.to(SETTING['device'])

            # Forward pass
            log_probs = model(x)  # (B, T, C)

            # Get best path (greedy decoding) by argmax over classes
            preds = log_probs.argmax(dim=-1)  # (B, T)

            # Collapse repeated and remove blanks (assuming blank=0)
            # This is a common CTC decoding post-processing:
            def decode_ctc(pred_seq):
                prev = None
                decoded = []
                for p in pred_seq:
                    if p != prev and p != 0:  # skip blanks and repeated
                        decoded.append(p.item())
                    prev = p
                return decoded

            for i in range(preds.size(0)):
                pred_seq = preds[i, :input_lengths[i]]  # cut to valid length

                pred_decoded = decode_ctc(pred_seq)
                target_seq = y[i, :target_lengths[i]].tolist()

                # Calculate phoneme error (Levenshtein distance)
                errors = levenshtein_distance(pred_decoded, target_seq)
                total_errors += errors
                total_phonemes += len(target_seq)

    PER = total_errors / total_phonemes if total_phonemes > 0 else 0.0
    return PER


def levenshtein_distance(seq1, seq2):
    # classic DP edit distance
    m, n = len(seq1), len(seq2)
    dp = [[0] * (n + 1) for _ in range(m + 1)]

    for i in range(m + 1):
        dp[i][0] = i
    for j in range(n + 1):
        dp[0][j] = j

    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if seq1[i - 1] == seq2[j - 1]:
                dp[i][j] = dp[i - 1][j - 1]
            else:
                dp[i][j] = 1 + min(
                    dp[i - 1][j],    # deletion
                    dp[i][j - 1],    # insertion
                    dp[i - 1][j - 1] # substitution
                )
    return dp[m][n]



def compute_cnn_output_lengths(model, input_lengths):
    """
    Computes the output time lengths after passing through the CNN part
    of ASRModel (init_conv + res_blocks).
    """
    if isinstance(input_lengths, torch.Tensor):
        input_lengths = input_lengths.tolist()

    new_lengths = []
    for length in input_lengths:
        dummy = torch.zeros(1, model.init_conv[0].in_channels, length)
        with torch.no_grad():
            out = model.init_conv(dummy)
            out = model.res_blocks(out)
        new_lengths.append(out.shape[-1])
    return torch.tensor(new_lengths, dtype=torch.long)


def beam_search_decoder(probs, beam_width=10, blank=0):
    """
    Beam search decoder for CTC.
    probs: (time, num_classes) - log probabilities
    """
    T, V = probs.shape
    beams = [(tuple(), 0.0)]  # (prefix, score)

    for t in range(T):
        new_beams = defaultdict(lambda: -float("inf"))
        for prefix, score in beams:
            for c in range(V):
                p = probs[t, c].item()
                new_prefix = prefix + (c,)
                new_beams[new_prefix] = max(new_beams[new_prefix], score + p)
        # Keep top beam_width
        beams = sorted(new_beams.items(), key=lambda x: x[1], reverse=True)[:beam_width]

    # Collapse repeats & remove blanks
    best_seq, _ = beams[0]
    collapsed = []
    prev = None
    for c in best_seq:
        if c != blank and c != prev:
            collapsed.append(c)
        prev = c
    return collapsed



#def decode_batch_beam_search(log_probs_batch, beam_width=10, blank=0):
#    """
#    Decode a batch of log_probs using beam search
#    log_probs_batch: (batch, time, vocab)
#    """
#    decoded = []
#    for lp in log_probs_batch:
#        seq = ctc_beam_search(lp, beam_width=beam_width, blank=blank)
#        decoded.append(seq)
#    return decoded



def save_checkpoint(model, optimizer, filename= 'checkpoint.pth.tar'):
  '''
  args:
    model: model on training
    optimizer: optimizer on optimizing
    filename: the path to save ongoing training states of model and optimizer
  '''
  checkpoint= {
      "state_dict": model.state_dict(),
      "optimizer": optimizer.state_dict()
  }
  print("= > Saving checkpoint")
  torch.save(checkpoint, filename)


def load_checkpoint(checkpoint, model, optimizer):
  '''
  args:
    checkpoint: a file where states of model and optimizer is saved
    model: instantiated model
    optimizer: instantiated optimizer
  '''
  print("= > Loading checkpoint")
  model = model.to(SETTING["device"])
  model.load_state_dict(checkpoint["state_dict"])
  optimizer.load_state_dict(checkpoint["optimizer"])

class EarlyStopping:
  def __init__(self, patience=  10, delta= 1e-5, mode= 'max'):
    self.patience=  patience # the number of epochs to wait observe loss
    self.counter= 0
    self.best_score= None
    self.early_stop= False
    self.delta= delta
    self.mode= mode

  def __call__(self, current):
    if self.best_score is None:
      self.best_score= current
      return False

    improvement= (current - self.best_score) if self.mode ==  "max" else (self.best_score - current)

    if improvement <=  self.delta:
      self.counter +=  1
      if self.counter >=  self.patience:
        self.early_stop= True
    else:
      self.best_score= current
      self.counter= 0

    return self.early_stop

# Train
def train_fn(train_loader, model, optimizer, loss_fn):
    model.train()
    total_loss = []

    inner_loop = tqdm(train_loader, desc='Batch', leave=False, position=1)

    for x, y, input_lengths, target_lengths in inner_loop:
      # Check for NaNs/Infs before placing it to device
      if torch.isnan(x).any() or torch.isinf(x).any():
        print("NaN or Inf in input!")
        raise ValueError("Invalud model input")

      # place data to device
      x, y = x.to(SETTING["device"]), y.to(SETTING["device"])
      input_lengths = compute_cnn_output_lengths(model, input_lengths).to(SETTING["device"])
      target_lengths = target_lengths.to(SETTING["device"])

      log_probs = model(x)  # (B, T, C)
      log_probs = log_probs.transpose(0, 1)  # (T, B, C)

      # Check for NaNs/Infs before loss
      if torch.isnan(log_probs).any() or torch.isinf(log_probs).any():
          print("NaN or Inf in model output!")
          raise ValueError("Invalid model output")

      y_concat = torch.cat([y[i][:target_lengths[i]] for i in range(y.size(0))])
      # calculate loss
      loss = loss_fn(log_probs, y_concat, input_lengths, target_lengths)

      # Check for NaNs/Infs among loss
      if torch.isnan(loss) or torch.isinf(loss) or torch.isnan(log_probs).any() or torch.isinf(log_probs).any():
        print("NaN or Inf in loss!")
        raise ValueError("Invalid loss")

      optimizer.zero_grad()
      loss.backward()
      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2)
      optimizer.step()


      total_loss.append(loss.item())

    return sum(total_loss) / len(total_loss)
