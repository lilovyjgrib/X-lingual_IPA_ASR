{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "reference: https://www.kaggle.com/code/mbmmurad/end-to-end-pipeline-cnn-rnn-model-with-ctc-loss"
      ],
      "metadata": {
        "id": "SmU6C2N11lIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "\n",
        "import os\n",
        "os.chdir('./drive/MyDrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzQFlleGTFJ2",
        "outputId": "3169e2f0-3ca8-43eb-d18e-36c8c5a04748"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### import"
      ],
      "metadata": {
        "id": "f9_8U10qZ03H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og37GU8EYXQt",
        "outputId": "8535c8ba-d9ca-4028-d7df-03611d9542c1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting params\n",
            "  Downloading params-0.9.0-py3-none-any.whl.metadata (631 bytes)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from params) (1.17.0)\n",
            "Downloading params-0.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: params\n",
            "Successfully installed params-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ya7kMqgJv_K",
        "outputId": "dace0770-7784-4f6f-d82c-e77221d1b315"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.2.1)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-4.0.0 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MBgjbdM6-GvG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot\n",
        "from IPython import display\n",
        "from jiwer import wer\n",
        "import params\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### read data\n",
        "define help function"
      ],
      "metadata": {
        "id": "2eh1FR-obeeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_TIMIT(path):\n",
        "  '''\n",
        "  path: path of TIMIT data(mfcc features, phoneme labels)\n",
        "  return:\n",
        "    feats: list of list for each audio samples\n",
        "    labels: list of list for each audio samples\n",
        "  '''\n",
        "\n",
        "  feats, labels = [], []\n",
        "  length_feats, length_labels = [], []\n",
        "\n",
        "  # read processed TIMIT data\n",
        "  # list of dictionarys with keys being 'mfcc', 'phonemes', 'path'\n",
        "  samples = torch.load(path, weights_only = False)\n",
        "  for idx in range(len(samples)):\n",
        "    feats.append(samples[idx]['mfcc'])\n",
        "    labels.append(samples[idx]['phonemes'])\n",
        "  return feats, labels\n"
      ],
      "metadata": {
        "id": "5DBThAEHbhhf"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "execute and review"
      ],
      "metadata": {
        "id": "hgNIqdSed4aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tO_ghkWBJ3mq",
        "outputId": "2a88a46f-b984-418c-f1b1-4aee92b579a4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'timit_mfcc_data.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split train / dev data\n",
        "path = r'timit_mfcc_data.pt'\n",
        "feats, labels = read_TIMIT(path)\n",
        "\n",
        "train_feats, dev_feats, train_labels, dev_labels = train_test_split(feats, labels)"
      ],
      "metadata": {
        "id": "ESPf-sMUdkMc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check mfcc feature matrix dimension\n",
        "print(f'MFCC feature matrix Shape(one audio sample):\\t{train_feats[-1].shape}')\n",
        "# check IPA repository\n",
        "print(f'phoneme labels(one audio sample):\\t{train_labels[-1]}')\n",
        "\n",
        "# seems like 'h#' marks sos and eos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l2g0WQoKorH",
        "outputId": "7c65f3f9-3799-4a6c-864b-e5c0142428aa"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MFCC feature matrix Shape(one audio sample):\t(97, 39)\n",
            "phoneme labels(one audio sample):\t['h#', 'dh', 'ix', 'n', 'ux', 'z', 'ey', 'zh', 'ix', 'n', 's', 'iy', 'hv', 'ay', 'axr', 'dcl', 'd', 'ey', 'gcl', 'g', 'r', 'ey', 'tcl', 'jh', 'er', 'nx', 'ax', 'l', 'ix', 's', 'tcl', 't', 'h#']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n'.join([f'num_frames:\\t{len(train_feats[0])}', f'num_labels:\\t{len(train_labels[0])}']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXGaIdZoL6VY",
        "outputId": "bab745c0-a2a5-41f6-b038-760a343cb543"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_frames:\t95\n",
            "num_labels:\t39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mark max length for mfcc features and labels\n",
        "max_len_feats = max([len(feat) for feat in feats])\n",
        "max_len_labels = max([len(label) for label in labels])"
      ],
      "metadata": {
        "id": "AthoPcjfR2Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### create IPA dictionary"
      ],
      "metadata": {
        "id": "MYRPHzmYKjn-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "define help function"
      ],
      "metadata": {
        "id": "SqvguFlNKd8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_IPAdictionary(labels):\n",
        "  '''\n",
        "  args:\n",
        "    labels: list of list\n",
        "  return: ipa2idx\n",
        "        dictionary of IPA_label: index\n",
        "  '''\n",
        "  ipas = set()\n",
        "  for label in labels:\n",
        "    ipas = ipas.union(set(label))\n",
        "  ipas = sorted(ipas)\n",
        "  ipas.remove('h#') # to assign index 1 to 'h#'\n",
        "\n",
        "  ipa2idx = {ipa:(idx+2) for idx, ipa in enumerate(ipas)}\n",
        "  ipa2idx['<blank>'] = 0\n",
        "  ipa2idx['h#'] = 1\n",
        "\n",
        "  return ipa2idx"
      ],
      "metadata": {
        "id": "rSTzPtvEKdZe"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "execute and review"
      ],
      "metadata": {
        "id": "NR9kwdQSLldm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ipa2idx = create_IPAdictionary(labels)\n",
        "print(*sorted(ipa2idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzCExD7TOt5k",
        "outputId": "fb3cd2be-d9fa-4aa7-fcc5-69c0ddc0719e"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<blank> aa ae ah ao aw ax ax-h axr ay b bcl ch d dcl dh dx eh el em en eng epi er ey f g gcl h# hh hv ih ix iy jh k kcl l m n ng nx ow oy p pau pcl q r s sh t tcl th uh uw ux v w y z zh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'the number of IPA labels in TIMIT:\\t {len(ipa2idx)}')\n",
        "print(f'Index of blank symbol <blank>\":\\t {ipa2idx[\"<blank>\"]}')\n",
        "print(f'Index of sos/eos label \"h#\":\\t {ipa2idx[\"h#\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ValF7gQOpW5",
        "outputId": "a0472214-02df-40fe-ccdc-121db0043b36"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the number of IPA labels in TIMIT:\t 62\n",
            "Index of blank symbol <blank>\":\t 0\n",
            "Index of sos/eos label \"h#\":\t 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset + pad\n",
        "define Dataset Class"
      ],
      "metadata": {
        "id": "bvm1LJp7Pz5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PhonemeASRDataset(Dataset):\n",
        "  def __init__(self, feats, labels, ipa2idx):\n",
        "    super(PhonemeASRDataset, self).__init__()\n",
        "    self.feats, self.labels = feats, labels\n",
        "    self.ipa2idx = ipa2idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.feats)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      feat, label = self.feats[idx], self.labels[idx]\n",
        "      label = [ipa2idx[ipa] for ipa in label]\n",
        "\n",
        "      return torch.tensor(feat), torch.tensor(label, dtype = torch.long)"
      ],
      "metadata": {
        "id": "v4C5kAvFP6ED"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define padding function"
      ],
      "metadata": {
        "id": "x7NqEpoNTGW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_collate(batch, pad_value_feat=0, pad_value_label=0):\n",
        "    '''\n",
        "      for collate_fn in DataLoader function\n",
        "\n",
        "    args:\n",
        "      batch: a list of tuples (mfcc, label)\n",
        "      return: padded_mfccs, padded_labels\n",
        "    '''\n",
        "\n",
        "    mfccs, labels = zip(*batch)\n",
        "\n",
        "    # find max length for mfcc(time step) and label in the current batch\n",
        "    max_len_feats = max(mfcc.shape[0] for mfcc in mfccs)\n",
        "    max_len_labels = max(label.shape[0] for label in labels)\n",
        "\n",
        "    # pad mfcc matrices and labels\n",
        "    padded_mfccs = [F.pad(mfcc, (0, 0, 0, max_len_feats - mfcc.shape[0]), value=pad_value_feat) for mfcc in mfccs]\n",
        "    padded_labels = [F.pad(label, (0, max_len_labels - label.shape[0]), value=pad_value_label) for label in labels]\n",
        "\n",
        "    # Stack the padded tensors\n",
        "    padded_mfccs = torch.stack(padded_mfccs)\n",
        "    padded_labels = torch.stack(padded_labels)\n",
        "\n",
        "    return padded_mfccs, padded_labels"
      ],
      "metadata": {
        "id": "S2BlBMgKS99x"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "execute and review"
      ],
      "metadata": {
        "id": "j9QDDW8XQ3xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = PhonemeASRDataset(train_feats, train_labels, ipa2idx = ipa2idx)\n",
        "train_loader = DataLoader(train_ds, batch_size = 32, # can adjust\n",
        "                          shuffle = True, collate_fn=pad_collate) # yields batch_size x max_len x num_feats as one training batch\n",
        "## should discover more about collate_fn keyword"
      ],
      "metadata": {
        "id": "kKY3IZhSS04Q"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, b = next(iter(train_loader))\n",
        "print(a.shape, b.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TsTyyh5W3Sj",
        "outputId": "b5ef8b12-2e82-4482-f902-08f97e47e5db"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 138, 39]) torch.Size([32, 54])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Loss Function"
      ],
      "metadata": {
        "id": "8Cu2m5ySw1S2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define CTC Loss Function\n",
        "def CTCLoss(y_true, y_pred):\n",
        "  '''\n",
        "  caculate CTC loss\n",
        "  args:\n",
        "    y_true:\n",
        "      gold labels for input sequence\n",
        "    y_pred:\n",
        "      predicted labels obtained from model\n",
        "  return:\n",
        "    loss value ## should discover more\n",
        "\n",
        "  '''\n",
        "\n",
        "  batch_len = tf.cast(tf.shape(y_true)[0], dtype = 'int64') # batch_size\n",
        "  input_length = tf.cast(tf.shape(y_pred)[1], dtype = 'int64') # prediction sequence length\n",
        "  label_length = tf.cast(tf.shape(y_true)[1], dtype = 'int64') # gold labels length\n",
        "\n",
        "  input_length = input_length * tf.ones(shape = (batch_len, 1), dtype = 'int64')\n",
        "  label_length = label_length * tf.ones(shape = (batch_len, 1), dtype = 'int64')\n",
        "  print(input_length, label_length)\n",
        "\n",
        "  loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "\n",
        "  return loss"
      ],
      "metadata": {
        "id": "ZUfVTq1gwy-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define CNN-RNN model"
      ],
      "metadata": {
        "id": "0F0mPuzOY4UY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def IPA_model(input_dim, ouput_dim, rnn_layers = 1, rnn_units = 128):\n",
        "  # model's input ## we are going to use mfcc features btw\n",
        "  input_spectrogram = layers.Input((None, input_dim), name = 'input')\n",
        "  # expand dimension to use CNN 2D\n",
        "  x = layers.Reshape((-1, input_dim, 1), name = 'example_dim')(input_spectrogram)\n",
        "\n",
        "  # CNN encoder\n",
        "  # Convolution layers 1\n",
        "  x = layers.Conv2D(\n",
        "      filters = 32, # can adjust\n",
        "      kernel_size = [11, 41], # can adjust\n",
        "      strides = [2, 2], # can adjust\n",
        "      padding = 'same',\n",
        "      use_bias = False,\n",
        "      name = 'conv_10',\n",
        "  )(x)\n",
        "\n",
        "  x = layers.Conv2D(\n",
        "      filters = 16,\n",
        "      kernel_size = [11, 41],\n",
        "      strides = [1, 1],\n",
        "      padding = 'same',\n",
        "      use_bias = False,\n",
        "      name = 'conv_11',\n",
        "  )(2)\n",
        "\n",
        "  ## where is pooling layer?\n",
        "\n",
        "  x = layers.BatchNormalization(name = 'conv_1_bn')(x)\n",
        "  x = layers.ReLU(name = 'conv_1_relu')\n",
        "\n",
        "  # Convolution layers 2\n",
        "    x = layers.Conv2D(\n",
        "      filters = 32, # can adjust\n",
        "      kernel_size = [11, 41], # can adjust\n",
        "      strides = [2, 2], # can adjust\n",
        "      padding = 'same',\n",
        "      use_bias = False,\n",
        "      name = 'conv_20',\n",
        "  )(x)\n",
        "\n",
        "  x = layers.Conv2D(\n",
        "      filters = 16,\n",
        "      kernel_size = [11, 41],\n",
        "      strides = [1, 1],\n",
        "      padding = 'same',\n",
        "      use_bias = False,\n",
        "      name = 'conv_21',\n",
        "  )(2)\n",
        "\n",
        "  ## where is pooling layer?\n",
        "\n",
        "  x = layers.BatchNormalization(name = 'conv_2_bn')(x)\n",
        "  x = layers.ReLU(name = 'conv_2_relu')\n",
        "\n",
        "  # Reshape output of CNN to feed RNN layers\n",
        "\n",
        "  # RNN encoder\n",
        "  for i in range(1, rnn_layers + 1):\n",
        "    gru = layers.GRU(\n",
        "        units = rnn_units, # can adjust\n",
        "        activation = 'ReLU', # what should we choose ?\n",
        "        recurrent_activation = 'sigmoid', # what should we choose ?\n",
        "        use_bias = True,\n",
        "        return_sequences = True,\n",
        "        reset_after = True,\n",
        "        name = f'gru_{i}',\n",
        "    )\n",
        "    x = layers.Bidirectional(\n",
        "        gru, name = f'bidirectional_{i}', merge_mode = 'concat'\n",
        "    )(x)\n",
        "\n",
        "    if i < rnn_layers:\n",
        "      x = layers.Dropout(rate = 0.5)(x)\n",
        "\n",
        "  # Dense lyaer\n",
        "  # 3 * MLP layers\n",
        "  x = layers.Dense(units = rnn_units * 2, name = 'dense_1')(x)\n",
        "  x = layers.ReLU(name = 'dense_1_relu')(x)\n",
        "  x = layers.Dropout(rate = 0.2)(x)\n",
        "\n",
        "  x = layers.Dense(units = rnn_units * 2, name = 'dense_1')(x)\n",
        "  x = layers.ReLU(name = 'dense_2_relu')(x)\n",
        "  x = layers.Dropout(rate = 0.2)(x)\n",
        "\n",
        "  x = layers.Dense(units = rnn_units * 2, name = 'dense_1')(x)\n",
        "  x = layers.ReLU(name = 'dense_3_relu')(x)\n",
        "  x = layers.Dropout(rate = 0.2)(x)\n",
        "\n",
        "  # Classifier\n",
        "  output = layers.Dense(units = output_dim + 1, activation = 'softmax')(x)\n",
        "\n",
        "\n",
        "  # Model\n",
        "  model = keras.Model(input_spectrogram, output, name = 'IPA_ASR')\n",
        "  # Optimizer\n",
        "  optimizer = keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "  model.compile(optimizer = optimizer, loss = CTCLoss)\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "JMbjbLyHii9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "execute; create model"
      ],
      "metadata": {
        "id": "pieOgpVA0TKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(\n",
        "    input_dim = fft_length // 2 + 1, ## we already have mfcc features\n",
        "    output_dim = len(ipa2idx),\n",
        "    rnn_units = 128,\n",
        ")\n",
        "\n",
        "model.summary(line_length = 100)"
      ],
      "metadata": {
        "id": "-ZpCT9gO0U9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class CNNEncoder(nn.Module):\n",
        "  #def __init__(self, in_channels = 3, out_channels = 16, latent_dim = 200,\n",
        "  #            act_fn = nn.ReLU(), dropout_p = 0.1):\n",
        "  #  super(CNNEncoder, self).__init__()\n",
        "    # define attributes of self\n",
        "  #  self.in_channels = in_channels\n",
        "  #  self.out_channels = out_channels\n",
        "  #  self.latent_dim = latent_dim\n",
        "  #  self.act_fn = act_fn\n",
        "\n",
        "    # define layers of self\n",
        "  #  self.conv1 = nn.Conv2d(self.in_channels, self.out_channels,\n",
        "  #                         kernel_size = 3,\n",
        "  #                         stride = 1,\n",
        "  #                         padding = 1, )\n",
        "  #  self.conv2 = nn.Conv2d(self.in_channels, self.out_channels,\n",
        "  #                         kernel_size = 3,\n",
        "  #                         stride = 1,\n",
        "  #                        padding = 1),\n",
        "  #  self.pool1 = nn.MaxPool2d(kernel_size = 5,\n",
        "  #                            stried = 2)\n",
        "\n",
        "\n",
        "  #  def forward(self, inputs):\n",
        "    # First iteration\n",
        "  #  x = self.conv2(self.conv1(inputs))\n",
        "  #  x = self.act_fn(self.pool1(x))\n",
        "    # Second interation\n",
        "  #  x = self.conv2(self.conv1(x))\n",
        "  #  x = self.act_fn(self.pool1(x))\n",
        "  #  return x\n"
      ],
      "metadata": {
        "id": "6GUGoV2vY6ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "execute and reivew"
      ],
      "metadata": {
        "id": "F3VuGxw8RImj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### call relevant dictionaries"
      ],
      "metadata": {
        "id": "NmbCuVKXZ5fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ipa2idx dictionary\n",
        "# should include sos '<', eos '>', pad '<pad>'\n",
        "\n",
        "# English to Yoruba dictionary\n",
        "# Yoruba to English dictionary"
      ],
      "metadata": {
        "id": "qwm8xP-dZ9xS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train\n",
        "set up device"
      ],
      "metadata": {
        "id": "_78q8LbJr5Pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "fOgD6P0rjbew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define train function"
      ],
      "metadata": {
        "id": "MMnHh9pAjcNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load & Pad data\n",
        "# 2. Initialize the Network\n",
        "# 2. Train / dev split\n",
        "# 3. Build vocabularies\n",
        "# 4. DataLoaders\n",
        "# 5. Instantiate & Train\n",
        "# 6. Inference on test\n",
        "# 7. post-hoc decode"
      ],
      "metadata": {
        "id": "EkmuKND9gbQU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}